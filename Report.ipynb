{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYPD Call Analysis for Crime Hotspots Prediction and Response Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Heet Gala - (Point of Contact)\n",
    "- Hemanth Chowdary Thammineni - https://github.com/ThammineniHemanthChowdary\n",
    "- Kunal Ahirrao - \n",
    "- Mansi Gopani - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In the bustling metropolis of New York City, ensuring public safety and efficient emergency response operations are paramount concerns for the New York City Police Department (NYPD) and other law enforcement agencies. The need to optimize response times to emergency calls is critical in effectively addressing incidents and maintaining public trust in the city's safety infrastructure. Recognizing this need, our project endeavors to harness the power of data analysis techniques to enhance the efficiency of NYPD response times.\n",
    "\n",
    "Our primary stakeholder, the NYPD, is tasked with the responsibility of safeguarding the city's residents and visitors, maintaining law and order, and swiftly responding to emergencies. By leveraging data analytics, we aim to support the NYPD in optimizing their emergency response operations, ultimately contributing to the enhancement of public safety in New York City.\n",
    "\n",
    "In collaboration with law enforcement agencies and with dispatchers as secondary stakeholders, our project focuses on analyzing NYPD call data and weather information. By examining patterns and trends in emergency call data alongside weather conditions, we seek to identify factors that influence response times. Through this analysis, we aim to develop insights and predictive models that can aid in the proactive allocation of resources and personnel to areas with higher incident probabilities.\n",
    "\n",
    "Our project holds the potential to benefit a wide range of stakeholders, including law enforcement agencies, government bodies, residents, and visitors. By developing predictive models for crime incidents and optimizing emergency response systems, we aspire to contribute to the creation of a safer and more secure environment for all individuals in New York City.\n",
    "\n",
    "Through our collaborative efforts and data-driven approach, we strive to empower law enforcement agencies with valuable insights that can drive actionable decisions, ultimately fostering a city that is better equipped to address emergencies and ensure the well-being of its citizens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Literature Review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our project, we address the stakeholder need of improving emergency response systems and enhancing public safety in New York City. The primary stakeholder is the New York City Police Department (NYPD), with secondary stakeholders including law enforcement agencies and dispatchers. The need for faster and more efficient emergency response times is critical for ensuring public safety and effective law enforcement operations.\n",
    "\n",
    "Our chosen methods, including data analysis, preprocessing, and machine learning modeling, are informed by prior work in the field of emergency response optimization and predictive modeling in law enforcement. Numerous studies have explored strategies for optimizing emergency response systems and improving response times in urban environments. These studies have highlighted the importance of leveraging real-time data, predictive modeling techniques, and optimization algorithms to enhance emergency response operations.\n",
    "\n",
    "Additionally, research on the influence of weather on response times has underscored the need to incorporate weather-related factors into emergency response planning and resource allocation. Adverse weather conditions can lead to delays in response times, affecting overall efficiency and effectiveness. Therefore, our decision to integrate weather data into our analysis aligns with prior work emphasizing the significance of weather-aware dispatching strategies and resource allocation.\n",
    "\n",
    "Furthermore, the application of machine learning techniques in law enforcement for predictive modeling and decision support has been widely explored in recent years. Studies have demonstrated the effectiveness of machine learning algorithms, such as random forest, decision trees, and K-nearest neighbors (KNN), in predicting crime incidents, emergency call volumes, and response times. Therefore, our selection of machine learning algorithms for predictive modeling is based on prior work showcasing their potential in addressing similar problems in law enforcement contexts.\n",
    "\n",
    "Overall, our approach is informed by prior research and best practices in the fields of emergency response optimization, weather impact analysis, and predictive modeling in law enforcement. By building upon existing knowledge and methodologies, we aim to contribute to the ongoing efforts to improve emergency response systems and enhance public safety in urban environments like New York City."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we describe the methods used for preprocessing our dataset before conducting analysis or modeling tasks. The preprocessing steps involved ensuring data consistency, extracting relevant information, and transforming the data into a suitable format for analysis.\n",
    "\n",
    "1. **Data Type Consistency**: The first preprocessing step involved ensuring that the 'RADIO_CODE' column was treated as strings by converting it using the `.astype(str)` method. This step was crucial to avoid any potential data type inconsistencies or errors in subsequent operations.\n",
    "\n",
    "2. **Extracting Unique Radio Codes**: We extracted the unique radio codes and their counts using the `value_counts()` method on the 'RADIO_CODE' column. This step provided insights into the distribution of radio codes within our dataset.\n",
    "\n",
    "3. **Filtering Data**: We filtered the dataset based on a predefined list of specific radio codes using the `.isin()` method, resulting in a new dataframe named `filtered_df`. This filtering step allowed us to focus our analysis on only the relevant radio codes.\n",
    "\n",
    "4. **Dimensionality Reduction**: Within `filtered_df`, we dropped unnecessary columns ('ADD_TS', 'DISP_TS', 'ARRIVD_TS', 'CLOSNG_TS', 'CIP_JOBS', 'GEO_CD_X', 'GEO_CD_Y', 'CAD_EVNT_ID') to reduce dimensionality and improve processing efficiency.\n",
    "\n",
    "5. **Creating Datetime Features**: We combined the 'INCIDENT_DATE' and 'INCIDENT_TIME' columns to create a new 'INCIDENT_DATETIME' column using `pd.to_datetime()` with the specified date-time format '%Y/%m/%d %H:%M:%S'. This step was essential for converting date and time information into a format suitable for analysis.\n",
    "\n",
    "6. **Extracting Temporal Components**: From the 'INCIDENT_DATETIME' column, we extracted various date and time components (year, month, day, hour, day of year, week, week of year, day of week, weekday, and quarter) using the `dt` accessor with different datetime properties. These components provided a more granular view of the temporal aspects of the data, which can be valuable for time-series analysis or trend identification.\n",
    "\n",
    "7. **Boolean Encoding**: We encoded boolean columns representing the radio codes ('RADIO_CODE_10V2', 'RADIO_CODE_10Y3', 'RADIO_CODE_75D', 'RADIO_CODE_75F', 'RADIO_CODE_75M', 'RADIO_CODE_75S', 'RADIO_CODE_75T') as integers using `.astype(int)`. This encoding step was necessary for machine learning models that require numerical inputs.\n",
    "\n",
    "These preprocessing and transformation steps were crucial for cleaning the data, extracting relevant information, and preparing it for further analysis or modeling tasks. They ensured data consistency, reduced dimensionality, and provided meaningful features for subsequent analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset Description:**\n",
    "- Source: The dataset is sourced from two primary sources: the New York City Police Department (NYPD) via the ICAD (Integrated Communications and Information System) - the NYPD's 911 system, and external weather data.\n",
    "- Reliability: The dataset's provenance from the NYPD itself indicates a high level of reliability and authenticity. The reliability of the external weather data depends on the source, which should be specified.\n",
    "\n",
    "**Dataset Content:**\n",
    "- Number of Rows: The combined dataset contains observations from both the NYPD calls dataset and the external weather dataset. The weather dataset comprises 978 entries.\n",
    "- Number of Columns: The total number of columns is the sum of columns from both datasets.\n",
    "- Features: The dataset includes features from the NYPD dataset such as identities, timestamps, geographic coordinates, incident descriptions, as well as weather-related features from the external weather dataset.\n",
    "\n",
    "**Data Types:**\n",
    "- The dataset comprises a mix of categorical, numerical, and temporal data types from both datasets, providing a multi-dimensional perspective of service calls along with weather conditions.\n",
    "\n",
    "**Key Columns:**\n",
    "- Incident Details: Columns such as borough, type, coordinates, and timestamps capture essential information about the incidents from the NYPD dataset.\n",
    "- Weather Information: Weather-related columns such as temperature, humidity, dew point, and windspeed provide additional context about the weather conditions at the time of each incident.\n",
    "\n",
    "**Unique Aspects:**\n",
    "- Integration of Weather Data: The integration of external weather data adds another dimension to the analysis, allowing for an examination of the influence of weather conditions on NYPD emergency responses.\n",
    "- Data Consistency: Ensuring consistency and reliability of the weather data is essential for accurate analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing and Data Transformation:**\n",
    "- **Datetime Conversion:** Date and time information from the NYPD response data were converted into datetime objects to facilitate precise temporal analysis.\n",
    "- **Data Merging:** External weather data were merged with the NYPD response data to investigate the influence of weather conditions on response times.\n",
    "- **Data Filtering:** The dataset was filtered based on radio codes to focus the analysis on specific types of incidents, reducing the dataset size for targeted examination.\n",
    "- **One-Hot Encoding:** Categorical variables, particularly the radio codes, were encoded using one-hot encoding to transform them into a binary format suitable for machine learning algorithms.\n",
    "\n",
    "**Modeling:**\n",
    "- **K-Nearest Neighbors (KNN):** Utilized for modeling the relationship between various features and response times, KNN is a non-parametric algorithm based on similarity measures between data points.\n",
    "- **Decision Tree:** Employed to build a predictive model for response times, Decision Tree recursively splits the dataset into subsets based on the most significant attribute, resulting in a tree-like structure for prediction.\n",
    "- **Random Forest:** Used for modeling response times, Random Forest constructs multiple decision trees during training and outputs the average prediction of the individual trees.\n",
    "\n",
    "**Evaluation:**\n",
    "- The performance of each model was assessed using appropriate metrics such as accuracy, mean absolute error (MAE), and R-squared to evaluate predictive power and performance.\n",
    "- The Decision Tree algorithm demonstrated the highest accuracy among the models tested, making it the preferred model for predicting response times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors (KNN):**\n",
    "- **Data Splitting:** The dataset was split into training and testing sets using a test size of 20% and a random state of 50 for reproducibility.\n",
    "- **Model Initialization:** A KNN classifier was initialized with 5 neighbors and trained on the training data.\n",
    "- **Cross-Validation:** 5-fold cross-validation was performed to assess the model's performance across different subsets of the data. The cross-validation scores ranged from 0.226 to 0.238, with a mean score of approximately 0.232.\n",
    "- **Parameter Adjustment:** The KNN classifier parameters were adjusted by setting the number of neighbors to 3, using distance-based weights, auto algorithm, leaf size of 40, and Euclidean distance metric.\n",
    "- **Model Evaluation:** The updated KNN classifier was trained on the training data and evaluated for accuracy on the test set. The achieved accuracy on the test set was 0.37, indicating moderate performance.\n",
    "\n",
    "**Decision Tree Classifier:**\n",
    "- **Model Creation:** A Decision Tree Classifier was created with a maximum depth of 500 and a random state of 300.\n",
    "- **Cross-Validation:** 5-fold cross-validation was conducted on the training data to assess the model's performance. The cross-validation scores ranged from 0.577 to 0.582, with a mean score of approximately 0.580.\n",
    "- **Feature Importance:** Feature importances were calculated using the feature_importances_ attribute of the trained decision tree classifier. The feature importance scores were obtained for various features, with latitude and longitude being the most important.\n",
    "- **Interpretation:** The Decision Tree Classifier showed a higher mean cross-validation score compared to KNN, indicating better overall performance. Feature importance analysis revealed the significant features driving the classification tasks, with latitude and longitude being the most influential.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we aimed to improve the efficiency of NYPD response times by leveraging data analysis techniques. Our primary stakeholders, the New York City Police Department (NYPD), seek to optimize emergency response operations to enhance public safety. \n",
    "\n",
    "Reflecting on our results, we have made significant progress in understanding the factors influencing response times and predicting crime incidents. However, there are limitations and areas for improvement.\n",
    "\n",
    "Regarding our stakeholder needs, our work addresses the NYPD's goal of optimizing emergency response operations. By analyzing NYPD call data alongside external weather data, we have gained insights into the influence of various factors, such as weather conditions, on response times. This analysis can inform resource allocation strategies and improve overall emergency response efficiency.\n",
    "\n",
    "However, it's important to acknowledge that our models, particularly the KNN and Decision Tree Classifier, achieved only moderate performance in predicting response times and crime incidents. While the Decision Tree Classifier showed better overall performance, there is still room for improvement.\n",
    "\n",
    "To further address stakeholder needs, future work could focus on refining the predictive models, exploring additional features, and incorporating more advanced machine learning techniques. Additionally, collaborating with stakeholders to gather more granular data and insights could enhance the relevance and effectiveness of our analysis.\n",
    "\n",
    "Overall, while our work provides valuable insights into the factors influencing NYPD response times, there is still work to be done to achieve our goals fully. Continued collaboration and iterative improvements will be essential in further enhancing emergency response operations and public safety in New York City."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitations:**\n",
    "\n",
    "1. **Data Quality:** While sourced from the NYPD, data may still have inaccuracies or omissions. Weather data coverage and accuracy could vary.\n",
    "  \n",
    "2. **Model Performance:** Achieved accuracy, particularly with KNN, is moderate and could be enhanced through advanced algorithms or feature engineering.\n",
    "  \n",
    "3. **Feature Importance:** Interpretation of feature importance from Decision Tree may not fully capture complex relationships.\n",
    "  \n",
    "4. **Stakeholder Needs:** While focused on improving NYPD response times, other law enforcement aspects or community engagement may require consideration.\n",
    "\n",
    "**Strategies for Improvement:**\n",
    "\n",
    "- **Data Augmentation:** Integrate additional datasets like demographics or historical crime data.\n",
    "  \n",
    "- **Advanced Techniques:** Explore advanced algorithms such as gradient boosting or neural networks.\n",
    "  \n",
    "- **Validation:** Conduct thorough validation and sensitivity analysis to assess model reliability.\n",
    "  \n",
    "- **Continuous Improvement:** Adopt an iterative approach for ongoing model refinement and relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Improving Model Accuracy:** Enhancing the accuracy of machine learning models for predicting response times is paramount. This could involve refining existing algorithms, exploring ensemble methods, or incorporating additional features for better predictions.\n",
    "\n",
    "2. **Real-Time Data Integration:** One significant limitation is the absence of real-time data integration, which could offer valuable insights for dynamically adjusting response strategies. Future efforts should focus on incorporating real-time data streams to enable more responsive and adaptive decision-making.\n",
    "\n",
    "3. **Enhanced Weather Data Analysis:** While weather data was integrated into the analysis, future work could delve deeper into more detailed weather information. Exploring the impact of specific weather events and public gatherings on emergency response times could provide valuable insights for optimizing resource allocation and deployment strategies.\n",
    "\n",
    "4. **Advanced Predictive Analytics:** Leveraging advanced predictive analytics techniques, such as time-series forecasting or anomaly detection, can further refine the understanding of response time patterns and enable proactive measures to improve emergency services.\n",
    "\n",
    "5. **Stakeholder Engagement and Collaboration:** Engaging with stakeholders, including law enforcement agencies, dispatchers, and government bodies, can provide valuable feedback and insights for refining the project's objectives and strategies. Collaboration with domain experts can also foster the development of more effective solutions tailored to the needs of end-users.\n",
    "\n",
    "6. **Scalability and Generalization:** As the project progresses, ensuring the scalability and generalizability of the models and methodologies is essential. Future work should focus on validating the performance of the models across diverse geographic locations and under varying operational conditions to ensure their robustness and applicability in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
